{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open VSCode and create a new project folder for your machine learning project.\n",
    "# Open the terminal in VSCode by going to Terminal > New Terminal.\n",
    "# Create a new environment using conda or pip. For example, to create a new environment with conda:\n",
    "#     conda create --name myenv\n",
    "#     conda activate myenv\n",
    "# Install the necessary packages for your machine learning project. For example, to install scikit-learn:\n",
    "#     conda install pandas numpy scikit-learn flask\n",
    "#     pip install -r requirements.txt             use this if you had initially loaded some packages to the file\n",
    "# Export the dependencies of your project by running the command:\n",
    "#     pip freeze > requirements.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>Table of Content:\n",
    "* [Import Libraries](#1)\n",
    "* [Load Data from Excel files](#2)\n",
    "* [Data Extraction](#3)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a> <br>\n",
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Analysis      \n",
    "import pandas as pd          # data analysis library for handling structured data             \n",
    "import numpy as np           # mathematical library for working with numerical data\n",
    "from metrics import *\n",
    "import os \n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt     # data visualization library for creating graphs and charts\n",
    "%matplotlib inline\n",
    "import seaborn as sns        # data visualization library based on matplotlib for creating more attractive visualizations\n",
    "import missingno as msno    #visualize missing data\n",
    "\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "\n",
    "pd.set_option('display.max_rows', 50) \n",
    "pd.set_option('display.max_columns', 500) \n",
    "pd.set_option('display.width', 1000) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a> <br>\n",
    "## Load Data from Two Excel Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> PROJECTG_Data EXCEL DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_url = r\"C:\\Users\\pault\\OneDrive - University of Oklahoma\\GRA - Bio-Manufacturing\\1. ML-Cytovance-OU-Research\\data\\raw\\ProjectG_Data.xlsx\"\n",
    "output_path = r\"C:\\Users\\pault\\OneDrive - University of Oklahoma\\GRA - Bio-Manufacturing\\1. ML-Cytovance-OU-Research\\data\\processed\"\n",
    "\n",
    "\n",
    "def load_data(file_url, sheet_name = None):\n",
    "    df = pd.read_excel(file_url, sheet_name=sheet_name, header=2)\n",
    "    df.drop([\"Unnamed: 15\", \"Timepoint (hr).1\", \"Production day\", \"Unnamed: 33\"], axis=1, inplace=True) # remove an empty column\n",
    "    columns = df.columns.to_list()\n",
    "    input_columns = ['input_' + col for col in columns[:14]]  # Rename columns up to 'OD600'\n",
    "    output_columns = ['output_' + col for col in columns[14:]]  # Rename columns from 'OD600' to the end\n",
    "    new_columns = input_columns + output_columns\n",
    "    df.columns = new_columns\n",
    "    return df\n",
    "\n",
    "def save_csv (df, filename:str, index = False):\n",
    "    df.to_csv(output_path + '\\\\' + filename + '.csv', index = index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and save data in sheet 1 - ProjectG_Data\n",
    "df_210623 = load_data(file_url, sheet_name=0)\n",
    "\n",
    "exp_210623_1 = df_210623.iloc[:22,]\n",
    "exp_210623_2 = df_210623.iloc[22:44,]\n",
    "exp_210623_3 = df_210623.iloc[44:66,]\n",
    "exp_210623_4 = df_210623.iloc[66:88,]\n",
    "\n",
    "save_csv(exp_210623_1, 'exp_210623_1')\n",
    "save_csv(exp_210623_2, 'exp_210623_2')\n",
    "save_csv(exp_210623_3, 'exp_210623_3')\n",
    "save_csv(exp_210623_4, 'exp_210623_4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and save data in sheet 2 - ProjectG_Data\n",
    "def load_data_2(file_url, sheet_name = None):\n",
    "    df = pd.read_excel(file_url, sheet_name=sheet_name, header=2)\n",
    "    df.drop([\"Unnamed: 15\", \"Timepoint (hr).1\", \"Production day\"], axis=1, inplace=True) # remove an empty column\n",
    "    columns = df.columns.to_list()\n",
    "    input_columns = ['input_' + col for col in columns[:14]]  # Rename columns up to 'OD600'\n",
    "    output_columns = ['output_' + col for col in columns[14:]]  # Rename columns from 'OD600' to the end\n",
    "    new_columns = input_columns + output_columns\n",
    "    df.columns = new_columns\n",
    "    return df\n",
    "\n",
    "\n",
    "# load data \n",
    "df_211130 = load_data_2(file_url, sheet_name=1)\n",
    "exp_211130_1 = df_211130.iloc[:21,]\n",
    "exp_211130_2 = df_211130.iloc[21:42,]\n",
    "exp_211130_3 = df_211130.iloc[42:63,]\n",
    "exp_211130_4 = df_211130.iloc[63:84,] \n",
    "\n",
    "# save data\n",
    "save_csv(exp_211130_1, 'exp_211130_1')\n",
    "save_csv(exp_211130_2, 'exp_211130_2')\n",
    "save_csv(exp_211130_3, 'exp_211130_3')\n",
    "save_csv(exp_211130_4, 'exp_211130_4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and save data in Sheet 3 - ProjectG_Data\n",
    "df_211013 = load_data_2(file_url, sheet_name=2)\n",
    "exp_211013_1 = df_211013.iloc[:19,]\n",
    "exp_211013_2 = df_211013.iloc[19:38,]\n",
    "exp_211013_3 = df_211013.iloc[38:57,]\n",
    "exp_211013_4 = df_211013.iloc[57:76]\n",
    "\n",
    "save_csv(exp_211013_1, 'exp_211013_1')\n",
    "save_csv(exp_211013_2, 'exp_211013_2')\n",
    "save_csv(exp_211013_3, 'exp_211013_3')\n",
    "save_csv(exp_211013_4, 'exp_211013_4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and save data in Sheet 4 - ProjectG_Data\n",
    "df_220822 = load_data_2(file_url, sheet_name=3)\n",
    "\n",
    "exp_220822_1 = df_220822.iloc[:20,]\n",
    "exp_220822_2 = df_220822.iloc[20:40,]\n",
    "exp_220822_3 = df_220822.iloc[40:60,]\n",
    "exp_220822_4 = df_220822.iloc[60:80,]\n",
    "\n",
    "save_csv(exp_220822_1, 'exp_220822_1')\n",
    "save_csv(exp_220822_2, 'exp_220822_2')\n",
    "save_csv(exp_220822_3, 'exp_220822_3')\n",
    "save_csv(exp_220822_4, 'exp_220822_4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> PROJECT_S EXCEL DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and save data in sheet 1 - Project_S\n",
    "file_url_2 = r\"C:\\Users\\pault\\OneDrive - University of Oklahoma\\GRA - Bio-Manufacturing\\1. ML-Cytovance-OU-Research\\data\\raw\\Project_S.xlsx\"\n",
    "\n",
    "\n",
    "def load_data_3(file_url, sheet_name = None, last_col_drop = None):\n",
    "    df = pd.read_excel(file_url, sheet_name=sheet_name, header=2)\n",
    "    df.drop([\"Unnamed: 15\", \"Timepoint (hr).1\", last_col_drop, \"Production day\",], axis=1, inplace=True) # remove an empty column\n",
    "    df['Temp'] = df['Temp'].apply(lambda x: x.replace('±1oC', '')) # remove the °C symbol from temperature values\n",
    "    df['pH setpoint'] = df['pH setpoint'].apply(lambda x: x.replace('±0.1', '')) # remove the ±0.1 from pH setpoint values\n",
    "    columns = df.columns.to_list()\n",
    "    input_columns = ['input_' + col for col in columns[:14]]  # Rename columns up to 'OD600'\n",
    "    output_columns = ['output_' + col for col in columns[14:]]  # Rename columns from 'OD600' to the end\n",
    "    new_columns = input_columns + output_columns\n",
    "    df.columns = new_columns\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and split into train/test sets (70%/30%)\n",
    "df_220315c1 = load_data_3(file_url_2, sheet_name=0, last_col_drop = 'Unnamed: 33')\n",
    "\n",
    "exp_220315c1_1 = df_220315c1.iloc[:19,]\n",
    "exp_220315c1_2 = df_220315c1.iloc[19:38,]\n",
    "exp_220315c1_3 = df_220315c1.iloc[38:57,]\n",
    "exp_220315c1_4 = df_220315c1.iloc[57:76,]\n",
    "exp_220315c1_5 = df_220315c1.iloc[76:95,]\n",
    "exp_220315c1_6 = df_220315c1.iloc[95:114,]\n",
    "\n",
    "  \n",
    "save_csv(exp_220315c1_1, 'exp_220315c1_1')\n",
    "save_csv(exp_220315c1_2, 'exp_220315c1_2')\n",
    "save_csv(exp_220315c1_3, 'exp_220315c1_3')\n",
    "save_csv(exp_220315c1_4, 'exp_220315c1_4')\n",
    "save_csv(exp_220315c1_5, 'exp_220315c1_5')\n",
    "save_csv(exp_220315c1_6, 'exp_220315c1_6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and save data in sheet 2 - Project_S\n",
    "df_220329c2 = load_data_3(file_url_2, sheet_name=1, last_col_drop = \"Unnamed: 35\")\n",
    "\n",
    "exp_220329c2_1 = df_220329c2.iloc[:25,]  # first row to 19th row\n",
    "exp_220329c2_2 = df_220329c2.iloc[25:50,]  # 19th row to 38th row\n",
    "exp_220329c2_3 = df_220329c2.iloc[50:75,]  # 38th row to 57th row\n",
    "exp_220329c2_4 = df_220329c2.iloc[75:100,]  # 57th row to 76th row\n",
    "exp_220329c2_5 = df_220329c2.iloc[100:125,]  # 76th row to 95th row\n",
    "exp_220329c2_6 = df_220329c2.iloc[125:150,]  # 95th row to 114th row\n",
    "\n",
    "\n",
    "save_csv(exp_220329c2_1, 'exp_220329c2_1')\n",
    "save_csv(exp_220329c2_2, 'exp_220329c2_2')\n",
    "save_csv(exp_220329c2_3, 'exp_220329c2_3')\n",
    "save_csv(exp_220329c2_4, 'exp_220329c2_4')\n",
    "save_csv(exp_220329c2_5, 'exp_220329c2_5')\n",
    "save_csv(exp_220329c2_6, 'exp_220329c2_6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and save data in sheet 3 - Project_S\n",
    "def load_data_3(file_url, sheet_name = None):\n",
    "    df = pd.read_excel(file_url, sheet_name=sheet_name, header=2)\n",
    "    df.drop([\"Unnamed: 15\", \"Timepoint (hr).1\", \"Production day\",], axis=1, inplace=True) # remove an empty column\n",
    "    df['Temp (oC)'] = df['Temp (oC)'].apply(lambda x: x.replace('±1', '')) # remove the °C symbol from temperature values\n",
    "    df['pH setpoint'] = df['pH setpoint'].apply(lambda x: x.replace('±0.1', '')) # remove the ±0.1 from pH setpoint values\n",
    "    columns = df.columns.to_list()\n",
    "    input_columns = ['input_' + col for col in columns[:14]]  # Rename columns up to 'OD600'\n",
    "    output_columns = ['output_' + col for col in columns[14:]]  # Rename columns from 'OD600' to the end\n",
    "    new_columns = input_columns + output_columns\n",
    "    df.columns = new_columns\n",
    "    return df\n",
    "\n",
    "\n",
    "df_220309demo = load_data_3(file_url_2, sheet_name=2)\n",
    "\n",
    "exp_220309demo_1 = df_220309demo.iloc[:23,]  # first row to 19th row\n",
    "exp_220309demo_2 = df_220309demo.iloc[23:46,]  # 19th row to 38th row\n",
    "exp_220309demo_3 = df_220309demo.iloc[46:69,]  # 38th row to 57th row\n",
    "exp_220309demo_4 = df_220309demo.iloc[69:92,]  # 57th row to 76th row\n",
    "\n",
    "\n",
    "save_csv(exp_220309demo_1, 'exp_220309demo_1')\n",
    "save_csv(exp_220309demo_2, 'exp_220309demo_2')\n",
    "save_csv(exp_220309demo_3, 'exp_220309demo_3')\n",
    "save_csv(exp_220309demo_4, 'exp_220309demo_4') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a> <br>\n",
    "## Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(r\"C:\\Users\\pault\\OneDrive - University of Oklahoma\\GRA - Bio-Manufacturing\\1. ML-Cytovance-OU-Research\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column names to check and their replacements\n",
    "columns_to_replace = {\n",
    "    'input_Vessel Type': 'input_vessel_type',\n",
    "    'input_Vessel Volume': 'input_vessel_volume',\n",
    "    'input_Vessel Name': 'input_vessel_name',\n",
    "    'input_Agitation (rpm)': 'input_agitation_rpm',\n",
    "    'input_DO (%)': 'input_DO_%',\n",
    "    'input_pH setpoint': 'input_pH_setpoint',\n",
    "    'input_Gas flow': 'input_gas_flow',\n",
    "    'input_Air (%)': 'input_air_%',\n",
    "    'input_O2': 'input_O2',\n",
    "    'input_Temp (oC)': 'input_Temp_c',\n",
    "    'input_Media type': 'input_media_type',\n",
    "    'input_Feed Type': 'input_feed_type',\n",
    "    'input_Glucose Limit': 'input_glucose_limit',\n",
    "    'output_OD600': 'output_OD600',\n",
    "    'output_WCW (g/L)': 'output_WCW_gl',\n",
    "    'output_Agitation': 'output_agitation',\n",
    "    'output_Air %': 'output_air_%',\n",
    "    'output_D0 %': 'output_D0_%',\n",
    "    'output_GasFlow': 'output_gasflow',\n",
    "    'output_O2.1': 'output_O2',\n",
    "    'output_Ph': 'output_Ph',\n",
    "    'output_Temp': 'output_Temp',\n",
    "    'output_Feed %': 'output_feed_%',\n",
    "    'output_Titre sample 1': 'output_titre_µgl_sample_1',\n",
    "    'output_Titre sample 2': 'output_titre_µgl_sample_2',\n",
    "    'output_Titre (mg/ml) (Sample 1)': 'output_titre_mg_ml_sample_1',\n",
    "    'output_Titre (mg/ml) Sample 2': 'output_titre_mg_ml_sample_2',\n",
    "    'output_Titre (µg/µl)': 'output_titre_µgl',\n",
    "    'output_Average Titre (mg/ml)': 'output_average_titre_mg_ml',\n",
    "    'output_Feed': 'output_feed',\n",
    "    'output_Glycerol (g/L)': 'output_glycerol_gl',\n",
    "    'output_Glucose (g/L)': 'output_glucose_gl',\n",
    "    'output_Acetate (mmol/L)': 'output_acetate_mmol_l',\n",
    "    'output_Phosphate (mmol/L)': 'output_phosphate_mmol_l',\n",
    "    'input_Agitation': 'input_agitation_rpm',\n",
    "    'input_DO': 'input_DO_%',\n",
    "    'input_Temp': 'input_Temp_c',\n",
    "    'input_Air': 'input_air_%',\n",
    "    'input_pH': 'input_pH_setpoint',\n",
    "    'output_Agitation.1': 'output_agitation',\n",
    "    'output_O2.1': 'output_O2',\n",
    "    'output_Temp.1': 'output_Temp',\n",
    "    'output_Titre (mg/ml)': 'output_titre_mg_ml',\n",
    "    'output_Titre (mg/ml).1': 'output_titre_mg_ml'\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "def get_data(experiment:str, num_range, index_col=None, parse_dates=True):\n",
    "    # Initialize a list to store the dataframes\n",
    "    df_list = []\n",
    "    \n",
    "    # Load the data\n",
    "    for i in range(1, num_range+1):\n",
    "        df = pd.read_csv(f\"data/processed/{experiment}_{i}.csv\", index_col=index_col, parse_dates=parse_dates)\n",
    "        df.rename(columns={col: columns_to_replace[col] for col in df.columns if col in columns_to_replace}, inplace=True)\n",
    "        if df.input_O2.dtypes == object:\n",
    "            df.input_O2 = df.input_O2.apply(lambda x: x[:1]).astype(float)\n",
    "        df.drop(columns=[col for col in df.columns if 'titre' in col.lower() ], inplace=True)   # drop all titre columns\n",
    "                    \n",
    "        df_list.append(df)\n",
    "    \n",
    "    return df_list\n",
    "\n",
    "# experiements\n",
    "exp_210623 = get_data('exp_210623', 4, index_col='input_Timepoint (hr)', parse_dates=True)\n",
    "exp_211013 = get_data('exp_211013', 4, index_col='input_Timepoint (hr)', parse_dates=True)\n",
    "exp_211130 = get_data('exp_211130', 4, index_col='input_Timepoint (hr)', parse_dates=True)\n",
    "exp_220309demo = get_data('exp_220309demo', 4, index_col='input_Timepoint (hr)', parse_dates=True)\n",
    "exp_220315c1 = get_data('exp_220315c1', 6, index_col='input_Timepoint (hr)', parse_dates=True)\n",
    "exp_220329c2 = get_data('exp_220329c2', 6, index_col='input_Timepoint (hr)', parse_dates=True)\n",
    "exp_220822 = get_data('exp_220822', 4, index_col='input_Timepoint (hr)', parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp_220315c1[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_column_order(df_list, reference_order):\n",
    "    \"\"\"\n",
    "    Aligns the column order of a list of dataframes to a reference order.\n",
    "\n",
    "    :param df_list: List of pandas DataFrames to standardize.\n",
    "    :param reference_order: List of column names in the desired order.\n",
    "    :return: List of DataFrames with standardized column order.\n",
    "    \"\"\"\n",
    "    standardized_dfs = []\n",
    "    for df in df_list:\n",
    "        # Reorder the columns according to the reference, dropping any that are not in the reference\n",
    "        standardized_df = df.reindex(columns=reference_order)\n",
    "        standardized_dfs.append(standardized_df)\n",
    "    return standardized_dfs\n",
    "\n",
    "\n",
    "reference_order = ['input_vessel_type', 'input_vessel_volume', 'input_vessel_name', 'input_agitation_rpm', 'input_DO_%', 'input_pH_setpoint', 'input_gas_flow', 'input_air_%', 'input_O2', 'input_Temp_c', 'input_media_type', 'input_feed_type', 'input_glucose_limit', 'output_OD600', 'output_WCW_gl', 'output_agitation', 'output_air_%', 'output_D0_%', 'output_gasflow', 'output_O2', 'output_Ph', 'output_feed_%', 'output_feed', 'output_Temp', 'output_glycerol_gl', 'output_glucose_gl', 'output_acetate_mmol_l', 'output_phosphate_mmol_l']\n",
    "\n",
    "exp_210623 = standardize_column_order(exp_210623, reference_order)\n",
    "exp_211013 = standardize_column_order(exp_211013, reference_order)\n",
    "exp_211130 = standardize_column_order(exp_211130, reference_order)\n",
    "exp_220309demo = standardize_column_order(exp_220309demo, reference_order)\n",
    "exp_220315c1 = standardize_column_order(exp_220315c1, reference_order)\n",
    "exp_220329c2 = standardize_column_order(exp_220329c2, reference_order)\n",
    "exp_220822 = standardize_column_order(exp_220822, reference_order)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding attribute name to each dataframe\n",
    "\n",
    "def add_attribute_name(df_list, df_name:str):\n",
    "    \"\"\"\n",
    "    Adds an attribute name to each DataFrame in a list.\n",
    "\n",
    "    :param df_list: List of pandas DataFrames to add attribute names to.\n",
    "    :param attribute_name: Name of the attribute to add.\n",
    "    :return: List of DataFrames with attribute names.\n",
    "    \"\"\"\n",
    "    for index, df in enumerate(df_list, start=1):\n",
    "        df.name = f\"{df_name}_{index}\"\n",
    "        \n",
    "    return df_list\n",
    "\n",
    "exp_210623 = add_attribute_name(exp_210623, 'exp_210623')\n",
    "exp_211013 = add_attribute_name(exp_211013, 'exp_211013')\n",
    "exp_211130 = add_attribute_name(exp_211130, 'exp_211130')\n",
    "exp_220309demo = add_attribute_name(exp_220309demo, 'exp_220309demo')\n",
    "exp_220315c1 = add_attribute_name(exp_220315c1, 'exp_220315c1')\n",
    "exp_220329c2 = add_attribute_name(exp_220329c2, 'exp_220329c2')\n",
    "exp_220822 = add_attribute_name(exp_220822, 'exp_220822')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the cleaned dataset.\n",
    "\n",
    "def save_dataframes(df_list, output_directory):\n",
    "    \"\"\"\n",
    "    Saves each dataframe in df_list to a CSV file in the specified output_directory.\n",
    "    The filename is derived from the 'name' attribute of each dataframe.\n",
    "\n",
    "    :param df_list: List of pandas DataFrames to be saved.\n",
    "    :param output_directory: The directory where CSV files will be saved.\n",
    "    \"\"\"\n",
    "    for df in df_list:\n",
    "        # Ensure the dataframe has a 'name' attribute set\n",
    "        if hasattr(df, 'name') and df.name:\n",
    "            filename = f\"{df.name}.csv\"\n",
    "            # Ensure the output directory ends with a '/'\n",
    "            if not output_directory.endswith('/'):\n",
    "                output_directory += '/'\n",
    "            # Construct the full path and save the dataframe\n",
    "            full_path = output_directory + filename\n",
    "            df.to_csv(full_path, index=True) \n",
    "        else:\n",
    "            print(\"DataFrame does not have a 'name' attribute or it's empty. Skipping...\")\n",
    "\n",
    "# Example usage\n",
    "# Assuming df_list is your list of dataframes and each dataframe has a 'name' attribute set\n",
    "output_directory = r\"data\\final_cleaned\"  # Specify your output directory here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "save_dataframes(exp_210623, output_directory)\n",
    "save_dataframes(exp_211013, output_directory)\n",
    "save_dataframes(exp_211130, output_directory)\n",
    "save_dataframes(exp_220309demo, output_directory)\n",
    "save_dataframes(exp_220315c1, output_directory)\n",
    "save_dataframes(exp_220329c2, output_directory)\n",
    "save_dataframes(exp_220822, output_directory)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c1065e887cc437d9280cab66f73a21fdac543e65443791bfb846601e6c934655"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
